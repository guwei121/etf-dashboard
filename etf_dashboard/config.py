"""
ç³»ç»Ÿé…ç½®ç®¡ç†

è´Ÿè´£ç®¡ç†ç³»ç»Ÿçš„å„ç§é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬æ•°æ®æºé…ç½®ã€æŠ€æœ¯æŒ‡æ ‡å‚æ•°ã€
ä¿¡å·è§„åˆ™é…ç½®å’Œç•Œé¢è®¾ç½®ç­‰ã€‚æ”¯æŒä»é…ç½®æ–‡ä»¶åŠ è½½å’Œç¯å¢ƒå˜é‡è¦†ç›–ã€‚
"""

import os
import json
import logging
from typing import Dict, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path
from datetime import datetime


@dataclass
class DataConfig:
    """æ•°æ®ç›¸å…³é…ç½®"""
    cache_dir: str = "data/cache"
    cache_expiry_hours: int = 24
    api_timeout: int = 30
    max_retries: int = 3
    retry_delay: float = 1.0
    data_sources: dict = None
    
    def __post_init__(self):
        if self.data_sources is None:
            self.data_sources = {
                "use_multi_source": True,
                "akshare": {
                    "enabled": True,
                    "priority": 1,
                    "timeout": 30,
                    "max_retries": 3
                },
                "tushare": {
                    "enabled": True,
                    "priority": 2,
                    "timeout": 30,
                    "max_retries": 3,
                    "token": "292f5bf5d3067a0d7bdfe9873e4df4b878c4d3ac690ed8743266855b76cf",
                    "proxy_url": "http://lianghua.nanyangqiankun.top"
                }
            }


@dataclass
class IndicatorConfig:
    """æŠ€æœ¯æŒ‡æ ‡é…ç½®"""
    ma_periods: list = None
    rsi_period: int = 14
    rsi_overbought: float = 70.0
    rsi_oversold: float = 30.0
    rsi_neutral: float = 50.0
    
    def __post_init__(self):
        if self.ma_periods is None:
            self.ma_periods = [5, 20, 60]


@dataclass
class SignalConfig:
    """ä¿¡å·è§„åˆ™é…ç½®"""
    max_drawdown_threshold: float = 0.20
    trend_strength_threshold: float = 0.6
    confidence_threshold: float = 0.5
    enable_trend_filter: bool = True
    enable_rsi_filter: bool = True
    enable_drawdown_filter: bool = True


@dataclass
class PortfolioConfig:
    """ç»„åˆç®¡ç†é…ç½®"""
    default_rebalance_threshold: float = 0.05
    config_file: str = "data/portfolio_config.json"
    auto_save: bool = True
    max_positions: int = 20


@dataclass
class UIConfig:
    """ç•Œé¢é…ç½®"""
    page_title: str = "ETFæŠ•èµ„ä»ªè¡¨ç›˜"
    page_icon: str = "ğŸ“ˆ"
    layout: str = "wide"
    sidebar_state: str = "expanded"
    theme: str = "light"
    chart_height: int = 400
    show_debug_info: bool = False


@dataclass
class LogConfig:
    """æ—¥å¿—é…ç½®"""
    level: str = "INFO"
    format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    file_path: str = "logs/etf_dashboard.log"
    max_file_size: int = 10 * 1024 * 1024  # 10MB
    backup_count: int = 5
    console_output: bool = True
    # æ–°å¢é…ç½®é¡¹
    enable_structured_logging: bool = True
    log_to_file: bool = True
    error_log_file: str = "logs/etf_dashboard_errors.log"
    performance_log_file: str = "logs/etf_dashboard_performance.log"
    enable_performance_logging: bool = True
    log_rotation_when: str = "midnight"  # æ—¥å¿—è½®è½¬æ—¶é—´
    log_rotation_interval: int = 1  # è½®è½¬é—´éš”
    enable_json_logging: bool = False  # JSONæ ¼å¼æ—¥å¿—
    sensitive_data_fields: list = None  # æ•æ„Ÿæ•°æ®å­—æ®µ
    
    def __post_init__(self):
        if self.sensitive_data_fields is None:
            self.sensitive_data_fields = ['password', 'token', 'key', 'secret']


class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    def __init__(self, config_file: str = "config/settings.json"):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file = config_file
        self.logger = logging.getLogger(__name__)
        
        # é»˜è®¤é…ç½®
        self.data = DataConfig()
        self.indicators = IndicatorConfig()
        self.signals = SignalConfig()
        self.portfolio = PortfolioConfig()
        self.ui = UIConfig()
        self.logging = LogConfig()
        
        # åŠ è½½é…ç½®
        self._load_config()
        self._apply_env_overrides()
    
    def _load_config(self) -> None:
        """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config_data = json.load(f)
                
                # æ›´æ–°å„æ¨¡å—é…ç½®
                if 'data' in config_data:
                    self._update_config(self.data, config_data['data'])
                
                if 'indicators' in config_data:
                    self._update_config(self.indicators, config_data['indicators'])
                
                if 'signals' in config_data:
                    self._update_config(self.signals, config_data['signals'])
                
                if 'portfolio' in config_data:
                    self._update_config(self.portfolio, config_data['portfolio'])
                
                if 'ui' in config_data:
                    self._update_config(self.ui, config_data['ui'])
                
                if 'logging' in config_data:
                    self._update_config(self.logging, config_data['logging'])
                
                self.logger.info(f"é…ç½®å·²ä»æ–‡ä»¶åŠ è½½: {self.config_file}")
            else:
                self.logger.info("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self._create_default_config()
                
        except Exception as e:
            self.logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
            self.logger.info("ä½¿ç”¨é»˜è®¤é…ç½®")
    
    def _apply_env_overrides(self) -> None:
        """åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–"""
        try:
            # æ•°æ®é…ç½®ç¯å¢ƒå˜é‡
            if os.getenv('ETF_CACHE_DIR'):
                self.data.cache_dir = os.getenv('ETF_CACHE_DIR')
            
            if os.getenv('ETF_CACHE_EXPIRY_HOURS'):
                self.data.cache_expiry_hours = int(os.getenv('ETF_CACHE_EXPIRY_HOURS'))
            
            # æ—¥å¿—é…ç½®ç¯å¢ƒå˜é‡
            if os.getenv('ETF_LOG_LEVEL'):
                self.logging.level = os.getenv('ETF_LOG_LEVEL').upper()
            
            if os.getenv('ETF_LOG_FILE'):
                self.logging.file_path = os.getenv('ETF_LOG_FILE')
            
            # ç•Œé¢é…ç½®ç¯å¢ƒå˜é‡
            if os.getenv('ETF_DEBUG'):
                self.ui.show_debug_info = os.getenv('ETF_DEBUG').lower() == 'true'
            
            self.logger.debug("ç¯å¢ƒå˜é‡è¦†ç›–å·²åº”ç”¨")
            
        except Exception as e:
            self.logger.error(f"åº”ç”¨ç¯å¢ƒå˜é‡è¦†ç›–å¤±è´¥: {str(e)}")
    
    def _update_config(self, config_obj: Any, config_dict: Dict[str, Any]) -> None:
        """æ›´æ–°é…ç½®å¯¹è±¡"""
        for key, value in config_dict.items():
            if hasattr(config_obj, key):
                setattr(config_obj, key, value)
    
    def _create_default_config(self) -> None:
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        try:
            # åˆ›å»ºé…ç½®ç›®å½•
            os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
            
            # ç”Ÿæˆé»˜è®¤é…ç½®
            default_config = {
                'data': asdict(self.data),
                'indicators': asdict(self.indicators),
                'signals': asdict(self.signals),
                'portfolio': asdict(self.portfolio),
                'ui': asdict(self.ui),
                'logging': asdict(self.logging)
            }
            
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, ensure_ascii=False, indent=2)
            
            self.logger.info(f"é»˜è®¤é…ç½®æ–‡ä»¶å·²åˆ›å»º: {self.config_file}")
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def save_config(self) -> None:
        """ä¿å­˜å½“å‰é…ç½®åˆ°æ–‡ä»¶"""
        try:
            config_data = {
                'data': asdict(self.data),
                'indicators': asdict(self.indicators),
                'signals': asdict(self.signals),
                'portfolio': asdict(self.portfolio),
                'ui': asdict(self.ui),
                'logging': asdict(self.logging)
            }
            
            # åˆ›å»ºé…ç½®ç›®å½•
            os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
            
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
            
            self.logger.info("é…ç½®å·²ä¿å­˜åˆ°æ–‡ä»¶")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
            raise
    
    def get_config_dict(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´é…ç½®å­—å…¸"""
        return {
            'data': asdict(self.data),
            'indicators': asdict(self.indicators),
            'signals': asdict(self.signals),
            'portfolio': asdict(self.portfolio),
            'ui': asdict(self.ui),
            'logging': asdict(self.logging)
        }
    
    def update_config(self, section: str, updates: Dict[str, Any]) -> None:
        """
        æ›´æ–°æŒ‡å®šé…ç½®èŠ‚
        
        Args:
            section: é…ç½®èŠ‚åç§° ('data', 'indicators', 'signals', 'portfolio', 'ui', 'logging')
            updates: æ›´æ–°çš„é…ç½®é¡¹
        """
        try:
            config_obj = getattr(self, section)
            self._update_config(config_obj, updates)
            self.logger.info(f"é…ç½®èŠ‚ {section} å·²æ›´æ–°")
            
        except AttributeError:
            raise ValueError(f"æ— æ•ˆçš„é…ç½®èŠ‚: {section}")
        except Exception as e:
            self.logger.error(f"æ›´æ–°é…ç½®èŠ‚å¤±è´¥ {section}: {str(e)}")
            raise


# å…¨å±€é…ç½®å®ä¾‹
config = ConfigManager()


def get_config() -> ConfigManager:
    """è·å–å…¨å±€é…ç½®å®ä¾‹"""
    return config


def setup_logging(config_manager: Optional[ConfigManager] = None) -> None:
    """
    è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
    
    Args:
        config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å…¨å±€é…ç½®
    """
    if config_manager is None:
        config_manager = config
    
    log_config = config_manager.logging
    
    try:
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = os.path.dirname(log_config.file_path)
        if log_dir:
            os.makedirs(log_dir, exist_ok=True)
        
        # åˆ›å»ºé”™è¯¯æ—¥å¿—ç›®å½•
        if log_config.log_to_file and log_config.error_log_file:
            error_log_dir = os.path.dirname(log_config.error_log_file)
            if error_log_dir:
                os.makedirs(error_log_dir, exist_ok=True)
        
        # åˆ›å»ºæ€§èƒ½æ—¥å¿—ç›®å½•
        if log_config.enable_performance_logging and log_config.performance_log_file:
            perf_log_dir = os.path.dirname(log_config.performance_log_file)
            if perf_log_dir:
                os.makedirs(perf_log_dir, exist_ok=True)
        
        # é…ç½®æ ¹æ—¥å¿—å™¨
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, log_config.level))
        
        # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
        for handler in root_logger.handlers[:]:
            root_logger.removeHandler(handler)
        
        # åˆ›å»ºæ ¼å¼å™¨
        if log_config.enable_json_logging:
            formatter = JsonFormatter()
        else:
            formatter = SensitiveDataFormatter(
                log_config.format,
                sensitive_fields=log_config.sensitive_data_fields
            )
        
        # ä¸»æ—¥å¿—æ–‡ä»¶å¤„ç†å™¨
        if log_config.log_to_file:
            from logging.handlers import TimedRotatingFileHandler
            
            file_handler = TimedRotatingFileHandler(
                log_config.file_path,
                when=log_config.log_rotation_when,
                interval=log_config.log_rotation_interval,
                backupCount=log_config.backup_count,
                encoding='utf-8'
            )
            file_handler.setFormatter(formatter)
            root_logger.addHandler(file_handler)
        
        # é”™è¯¯æ—¥å¿—æ–‡ä»¶å¤„ç†å™¨
        if log_config.log_to_file and log_config.error_log_file:
            from logging.handlers import RotatingFileHandler
            
            error_handler = RotatingFileHandler(
                log_config.error_log_file,
                maxBytes=log_config.max_file_size,
                backupCount=log_config.backup_count,
                encoding='utf-8'
            )
            error_handler.setLevel(logging.ERROR)
            error_handler.setFormatter(formatter)
            root_logger.addHandler(error_handler)
        
        # æ€§èƒ½æ—¥å¿—å¤„ç†å™¨
        if log_config.enable_performance_logging and log_config.performance_log_file:
            perf_logger = logging.getLogger('performance')
            perf_handler = logging.FileHandler(log_config.performance_log_file, encoding='utf-8')
            perf_handler.setFormatter(formatter)
            perf_logger.addHandler(perf_handler)
            perf_logger.setLevel(logging.INFO)
            perf_logger.propagate = False  # ä¸ä¼ æ’­åˆ°æ ¹æ—¥å¿—å™¨
        
        # æ§åˆ¶å°å¤„ç†å™¨
        if log_config.console_output:
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            
            # æ§åˆ¶å°åªæ˜¾ç¤ºWARNINGåŠä»¥ä¸Šçº§åˆ«
            console_handler.setLevel(logging.WARNING)
            root_logger.addHandler(console_handler)
        
        # è®¾ç½®ç¬¬ä¸‰æ–¹åº“çš„æ—¥å¿—çº§åˆ«
        logging.getLogger('urllib3').setLevel(logging.WARNING)
        logging.getLogger('requests').setLevel(logging.WARNING)
        logging.getLogger('matplotlib').setLevel(logging.WARNING)
        logging.getLogger('plotly').setLevel(logging.WARNING)
        
        logging.info("å¢å¼ºæ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        logging.info(f"æ—¥å¿—çº§åˆ«: {log_config.level}")
        logging.info(f"ä¸»æ—¥å¿—æ–‡ä»¶: {log_config.file_path}")
        if log_config.error_log_file:
            logging.info(f"é”™è¯¯æ—¥å¿—æ–‡ä»¶: {log_config.error_log_file}")
        if log_config.enable_performance_logging:
            logging.info(f"æ€§èƒ½æ—¥å¿—æ–‡ä»¶: {log_config.performance_log_file}")
        
    except Exception as e:
        print(f"æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        # ä½¿ç”¨åŸºæœ¬é…ç½®ä½œä¸ºåå¤‡
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )


class SensitiveDataFormatter(logging.Formatter):
    """æ•æ„Ÿæ•°æ®è¿‡æ»¤æ ¼å¼å™¨"""
    
    def __init__(self, fmt=None, datefmt=None, sensitive_fields=None):
        super().__init__(fmt, datefmt)
        self.sensitive_fields = sensitive_fields or []
    
    def format(self, record):
        # è¿‡æ»¤æ•æ„Ÿæ•°æ®
        if hasattr(record, 'msg') and isinstance(record.msg, str):
            for field in self.sensitive_fields:
                if field.lower() in record.msg.lower():
                    record.msg = record.msg.replace(field, '*' * len(field))
        
        return super().format(record)


class JsonFormatter(logging.Formatter):
    """JSONæ ¼å¼æ—¥å¿—æ ¼å¼å™¨"""
    
    def format(self, record):
        import json
        from datetime import datetime
        
        log_entry = {
            'timestamp': datetime.fromtimestamp(record.created).isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        # æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if record.exc_info:
            log_entry['exception'] = self.formatException(record.exc_info)
        
        # æ·»åŠ é¢å¤–å­—æ®µ
        if hasattr(record, 'extra_fields'):
            log_entry.update(record.extra_fields)
        
        return json.dumps(log_entry, ensure_ascii=False)


def get_performance_logger():
    """è·å–æ€§èƒ½æ—¥å¿—å™¨"""
    return logging.getLogger('performance')


def log_performance(func_name: str, duration: float, **kwargs):
    """è®°å½•æ€§èƒ½æ—¥å¿—"""
    perf_logger = get_performance_logger()
    extra_info = ', '.join([f"{k}={v}" for k, v in kwargs.items()])
    perf_logger.info(f"PERF: {func_name} took {duration:.3f}s {extra_info}")


def create_structured_log_entry(
    level: str,
    message: str,
    category: str = None,
    component: str = None,
    **extra_fields
) -> Dict[str, Any]:
    """
    åˆ›å»ºç»“æ„åŒ–æ—¥å¿—æ¡ç›®
    
    Args:
        level: æ—¥å¿—çº§åˆ«
        message: æ—¥å¿—æ¶ˆæ¯
        category: æ—¥å¿—ç±»åˆ«
        component: ç»„ä»¶åç§°
        **extra_fields: é¢å¤–å­—æ®µ
        
    Returns:
        ç»“æ„åŒ–æ—¥å¿—å­—å…¸
    """
    log_entry = {
        'timestamp': datetime.now().isoformat(),
        'level': level.upper(),
        'message': message
    }
    
    if category:
        log_entry['category'] = category
    
    if component:
        log_entry['component'] = component
    
    log_entry.update(extra_fields)
    
    return log_entry